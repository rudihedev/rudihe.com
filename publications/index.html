<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Rudi Heriansyah</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link rel="stylesheet" href="/style.css" />
  </head>
  <body>
    <div>
      <main class="max-w-[600px] mx-auto mt-10">
        <!-- <main class="max-w-[600px] mx-auto mt-8 pl-5 px-4"> -->

        <nav>
          <div class="nav-left">
            <a href="/">Home</a>
          </div>
          <div class="nav-right">
            <a href="/projects">Projects</a>
            <a href="/publications">Publications</a>
            <a href="/contact">Contact</a>
          </div>
        </nav>

        <div class="space-y-4">
            <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/ieee.png"
                alt="IEEE"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Hyperparameter Tuning to Improve Object Detection Performance in Handwritten Images
              </h4>
              <p class="text-base text-gray-600">
                Muhammad Haviz Irfani, Samsuryadi, Abdiansah, Rudi Heriansyah, 2024
              </p>
              <p class="text-sm mt-2 text-gray-600">
                Object detection in handwritten images is a complex challenge due to variations in writing styles, letter sizes, and environmental conditions when handwriting is created. The You Only Look Once (YOLO) method has shown promising results in detecting objects in real-time in various types of images. However, YOLO performance is highly dependent on optimal hyperparameter tuning for a specific detection task. Hyperparameter tuning is a crucial step in improving object detection performance, especially in the context of handwritten images. This research aims to optimize YOLO hyperparameters to increase the accuracy of object detection in handwritten images. Some tuned hyperparameters are momentum, weight_decay, learning rate, batch size, and epoch. This research was carried out for 49 training sessions using the YOLOv8 and CUDA version 11.8 frameworks with a primary dataset obtained of 44 pieces of diverse handwriting, including various variations of handwriting styles that were consistent in lighting conditions, type and size of paper and pen, form format, and healthy physical and psychological conditions. 
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.1109/ICICYTA64807.2024.10913390"
                >https://doi.org/10.1109/ICICYTA64807.2024.10913390</a
              >
            </div>
          </div>

            <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/ieee.png"
                alt="IEEE"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Detection and Classification Disease Citrus Nobilis Lour Using Convolutional Neural Network Method
              </h4>
              <p class="text-base text-gray-600">
                Muhammad Tsaqib, Zaid Romegar Mair, Gasim, Rudi Heriansyah, Herri Setiawan, 2024
              </p>
              <p class="text-sm mt-2 text-gray-600">
                Citrus Nobilis Lour, sometimes known as Siamese oranges, is the primary fruit in many nations and one of the fruits with the highest commercial worth [1]. This study makes use of data from 2000 photos, 500 photos each classthat is, the class of leaves affected by cancer, the class of leaves affected by worm disease, the class of leaves affected by Citrus Vein Phloem Degeneration (CVPD), and the class of healthy leaves after which the VGG-16 model is trained to identify and categorize the illness. This study employs Adam optimization and Stochastic Gradient Descent (SGD) optimization with VGG-16. Three trials with SGD and two trials with Adam were included in the research. This research yielded train accuracy of 72% in 40 epochs using SGD optimization and 90% in 10 epochs using Adam optimization, along with a 54% classification accuracy.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.1109/ICITRI62858.2024.10698811"
                >https://doi.org/10.1109/ICITRI62858.2024.10698811</a
              >
            </div>
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/sinta2.png"
                alt="SINTA 2"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Improving the Accuracy of Concrete Mix Type Recognition with ANN
                and GLCM Features Based on Image Resolution
              </h4>
              <p class="text-base text-gray-600">
                Gasim, Rudi Heriansyah, Shinta Puspasari, Muhammad Haviz Irfani,
                Evi Purnamasari, Indah Permatasari, Samsuryadi, 2024
              </p>
              <p class="text-sm mt-2 text-gray-600">
                Concrete is an essential construction material widely used for
                its strength and durability. However, identifying its mix type
                often relies on conventional methods that are less efficient and
                accurate. This research evaluates the impact of image resolution
                on the accuracy of concrete mix type recognition using
                Artificial Neural Network (ANN) and Gray-Level Co-Occurrence
                Matrix (GLCM) features. The method involves analyzing con- crete
                images at four resolutions: 300 × 300, 500 × 500, 700 × 700, and
                900 × 900 pixels. This study emphasizes the novelty of exploring
                the effect of varying image resolutions on concrete mix type
                recognition accuracy. While ANN and GLCM are widely used in
                image classification, their application to investigate the
                resolution’s role in concrete recognition remains underexplored
                in the literature. This focus contributes new insights to
                improving automated recognition systems for concrete mix types,
                enhancing accuracy and efficiency in the construction industry.
                The experimental results show a clear correlation between im-
                age resolution and recognition accuracy. Images with resolutions
                of 300 × 300 pixels yield an accuracy of 45%, which is
                inadequate for reliable classification. Accuracy improves with
                higher resolutions, reaching 62.5% and 70% for 500 × 500 and 700
                × 700 pixels, respec- tively. Interestingly, at 900 × 900
                pixels, the accuracy slightly decreases to 68%, suggesting that
                excessively high resolutions may introduce redundant details.
                The study identifies 700 × 700 pixels as the optimal resolution
                for accurate concrete mix classification. Future work should
                refine feature selection and preprocessing techniques to further
                optimize accuracy and computational efficiency.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.20895/infotel.v17i1.1201"
                >https://doi.org/10.20895/infotel.v17i1.1201</a
              >
            </div>
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/sinta2.png"
                alt="SINTA 2"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Real-time Vehicle Surveillance System Based on Image Processing
                and Short Message Service
              </h4>
              <p class="text-base text-gray-600">
                Agustinus Deddy Arief Wibowo, Rudi Heriansyah, 2021
              </p>
              <p class="text-sm mt-2 text-gray-600">
                This paper proposes a real-time vehicle surveillance system
                based on image processing approach tailored with short message
                service. A background subtraction, color balancing, chain code
                based shape detection, and blob filtering are used to detect
                suspicious moving human around the parked vehicle. Once
                detected, the developed system will generate a warning
                notification to the owner by sending a short message to his
                mobile phone. The current frame of video image will also be
                stored and be sent to the owner e-mail for further checking and
                investigation. Last stored image will be displayed in a
                centralized monitoring website, where the status of the vehicle
                also can be monitored at the same time. When necessary, the
                stored images can be used during investigation process to assist
                the authority to take further legal actions.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.30595/juita.v9i2.8728"
                >https://doi.org/10.30595/juita.v9i2.8728
              </a>
            </div>
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/sinta2.png"
                alt="SINTA 2"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Performance Evaluation of Digital Image Processing by Using
                Scilab
              </h4>
              <p class="text-base text-gray-600">
                Rudi Heriansyah, Wahyu Mulyo Utomo, 2021
              </p>
              <p class="text-sm mt-2 text-gray-600">
                Scilab is an open-source, cross-platform computational
                environment software available for academic and research
                purposes as a free of charge alternative to the matured
                computational copyrighted software such as MATLAB. One of
                important library available for Scilab is image processing
                toolbox dedicated solely for image and video processing. There
                are three major toolboxes for this purpose: Scilab image
                processing toolbox (SIP), Scilab image and video processing
                toolbox (SIVP) and recently image processing design toolbox
                (IPD). The target discussion in this paper is SIVP due to its
                vast use out there and its capability to handle streaming video
                file as well (note that IPD also supports video processing).
                Highlight on the difference between SIVP and IPD will also be
                discussed. From testing, it is found that in term of looping
                test, Octave and FreeMat are faster than Scilab. However, when
                converting RGB image to grayscale image, Scilab outperform
                Octave and FreeMat.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.30595/juita.v9i2.8434 "
                >https://doi.org/10.30595/juita.v9i2.8434
              </a>
            </div>
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/taylor.png"
                alt="Taylor"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Quantitative Defect Characterization for Passive Thermography
                Application
              </h4>
              <p class="text-base text-gray-600">
                Rudi Heriansyah, S.A.R. Abu-Bakar, A. Nahhas, 2015
              </p>
              <p class="text-sm mt-2 text-gray-600">
                This article proposes a new method for characterizing subsurface
                defects in high temperature wall by means of passive
                thermography. The method enables a fast and reliable
                quantitative defect characterization. Ten informative parameters
                have been proposed for this purpose based on temperature
                behavior on the outer surface wall of a petrochemical boiler.
                Multilayer perceptron neural network has been trained to
                characterize quantitatively three defect properties: thickness,
                length, and width of the defect. From an extensive testing of
                the method, it has been shown that the method is able to
                characterize the defect properties, which actually we believe is
                a new approach in passive thermography application.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.1080/09349847.2015.1012248"
                >https://doi.org/10.1080/09349847.2015.1012248</a
              >
            </div>
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/elsevier.png"
                alt="Elsevier"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Defect detection in thermal image for nondestructive evaluation
                of petrochemical equipments
              </h4>
              <p class="text-base text-gray-600">
                Rudi Heriansyah, S.A.R. Abu-Bakar, 2009
              </p>
              <p class="text-sm mt-2 text-gray-600">
                This paper proposes a method for segmenting defects depicted in
                a thermal image of petrochemical equipments by means of passive
                thermography. The technique first enhances the contrast of the
                defects based on local neighborhood pixel intensity operation.
                This local intensity operation works in two modes, either
                brightening the pixels for detecting hot spots or darkening the
                pixels for detecting cold spots. The next step is to segment the
                defects using simple histogram-based thresholding techniques. We
                propose three thresholding methods: mean absolute thresholding
                (MAT), mean relative thresholding (MRT), and minimum frequency
                thresholding (MFT). Compared to existing techniques, we found
                that our proposed methods have better detection and success
                rate.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.1016/j.ndteint.2009.06.008"
                >https://doi.org/10.1016/j.ndteint.2009.06.008</a
              >
            </div>            
          </div>

          <div
            class="flex items-start gap-4 bg-gray-150 p-5 rounded-xl shadow hover:shadow-lg transition"
          >
            <div class="w-20 h-20 flex-shrink-0">
              <img
                src="/logos/utm-press.png"
                alt="UTM Press"
                class="w-full h-full object-contain"
              />
            </div>

            <div class="flex-1">
              <h4 class="text-lg font-bold text-blue-600">
                Neural Network Paradigm for Classification of Defects on PCB
              </h4>
              <p class="text-base text-gray-600">
                Rudi Heriansyah, Syed Abdul Rahman Al-Attas, M. M. A. Zabidi, 2003
              </p>
              <p class="text-sm mt-2 text-gray-600">
                A new technique is proposed to classify the defects that could occur on the PCB usingneural network paradigm. The algorithms to segment the image into basic primitive patterns, enclosingthe primitive patterns, patterns assignment, patterns normalization, and classification have been developedbased on binary morphological image processing and Learning Vector Quantization (LVQ) neuralnetwork. Thousands of defective patterns have been used for training, and the neural network is testedfor evaluating its performance. A defective PCB image is used to ensure the function of the proposed technique.
              </p>
              <a
                class="text-xs space-y-4 font-bold"
                href="https://doi.org/10.11113/jt.v39.465"
                >https://doi.org/10.11113/jt.v39.465</a
              >
            </div>
        </div>
      </main>

      <footer>2025 (c) Rudi Heriansyah | All Rights Reserved</footer>
    </div>
  </body>
</html>
